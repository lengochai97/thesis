{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4.1. News Click Counts.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lengochai97/thesis/blob/master/notebooks/feature_construction/41_News_Click_Counts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0S-b63NesNq",
        "colab_type": "text"
      },
      "source": [
        "# Connect to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mA8N4fsj8cY3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "\n",
        "import google.colab.drive\n",
        "\n",
        "google.colab.drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xR1ujuEeedLa",
        "colab_type": "text"
      },
      "source": [
        "# Install Spark and dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzDLzKhZkCIf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "os.environ['HADOOP_VERSION'] = '2.7'\n",
        "os.environ['JAVA_HOME'] = '/usr/lib/jvm/java-8-openjdk-amd64'\n",
        "os.environ['SPARK_HOME'] = '/opt/spark'\n",
        "os.environ['SPARK_VERSION'] = '2.4.3'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6xVWiMvy_cJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "\n",
        "!wget -qN https://archive.apache.org/dist/spark/spark-$SPARK_VERSION/spark-$SPARK_VERSION-bin-hadoop$HADOOP_VERSION.tgz\n",
        "!tar -xzf spark-$SPARK_VERSION-bin-hadoop$HADOOP_VERSION.tgz -C /opt\n",
        "!rm spark-$SPARK_VERSION-bin-hadoop$HADOOP_VERSION.tgz\n",
        "!rm -rf /opt/spark\n",
        "!ln -s /opt/spark-$SPARK_VERSION-bin-hadoop$HADOOP_VERSION /opt/spark\n",
        "!pip install -q findspark"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J13MUPQVtZiF",
        "colab_type": "text"
      },
      "source": [
        "# Create SparkSession"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1Bm1_F32y9B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import findspark\n",
        "\n",
        "findspark.init()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvrAOXX10VgF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.master('local[*]').getOrCreate()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bLvSe5Nt5FX",
        "colab_type": "text"
      },
      "source": [
        "# Read files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUG5bFA3t-M2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "\n",
        "import pyspark.sql.functions as F\n",
        "import pyspark.sql.types as T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "141y1nsXt4lm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_PATH = '/content/gdrive/My Drive/dataset/adressa/one_week'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-rwHQQ7tJ2b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(os.path.join(DATA_PATH, 'schema', 'samples.json')) as file:\n",
        "  sample_schema = T.StructType.fromJson(json.load(file))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QsFj_O0tVKR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_sample = spark.read.json(os.path.join(DATA_PATH, 'samples'), schema=sample_schema)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcge4yewpiKG",
        "colab_type": "text"
      },
      "source": [
        "# Extract (`newsId`, `time`) pairs and bucketize by `time`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcSgNdn9vnQp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TIME_BUCKET_RANGE = 60"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWiSNFZzzhr9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_sample_bucketized = (\n",
        "    df_sample\n",
        "    .select(\n",
        "        F.column('newsId'),\n",
        "        F.column('time'),\n",
        "        (F.column('time') / TIME_BUCKET_RANGE).cast(T.LongType()).alias('timeBucket'),\n",
        "        F.column('clickLabel'),\n",
        "    )\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWIToKAMvrRf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_news_click_counts_bucketized = (\n",
        "    df_sample_bucketized\n",
        "    .groupBy(F.column('newsId'), F.column('timeBucket'))\n",
        "    .agg(F.sum('clickLabel').alias('clickCount'))\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjKouh-OX60-",
        "colab_type": "text"
      },
      "source": [
        "# Calculate news click counts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zoYqfWzvtCb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.sql import Window"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8f-vzOGpwK_9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_news_click_count(df_news_click_counts_bucketized, time_tag, time_delta):\n",
        "  return (\n",
        "      df_news_click_counts_bucketized\n",
        "      .withColumn(\n",
        "          f'newsClickCount{time_tag}',\n",
        "          F.sum(F.column('clickCount')).over(\n",
        "              Window\n",
        "              .partitionBy('newsId')\n",
        "              .orderBy('timeBucket')\n",
        "              .rangeBetween(-(time_delta // TIME_BUCKET_RANGE), -1)\n",
        "          ),\n",
        "      )\n",
        "      .fillna(0, subset=[f'newsClickCount{time_tag}'])\n",
        "      .select(\n",
        "          F.column('newsId'),\n",
        "          F.column('timeBucket'),\n",
        "          F.column(f'newsClickCount{time_tag}')\n",
        "      )\n",
        "  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-gx1kyzW_9C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "time_info = (\n",
        "    ('1H', 3600),\n",
        "    ('6H', 21600),\n",
        "    ('1D', 86400),\n",
        "    ('1W', 604800),\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75xtNOKdZ8I4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "news_click_counts_column = (\n",
        "    'newsClickCount1H',\n",
        "    'newsClickCount6H',\n",
        "    'newsClickCount1D',\n",
        "    'newsClickCount1W',\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaZHhmbnXG4u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_news_click_counts = (\n",
        "    df_sample_bucketized\n",
        "    .select(\n",
        "        F.column('newsId'),\n",
        "        F.column('time'),\n",
        "        F.column('timeBucket'),\n",
        "    )\n",
        "    .dropDuplicates(subset=['newsId', 'time'])\n",
        ")\n",
        "\n",
        "for time_tag, time_delta in time_info:\n",
        "  df_news_click_counts = (\n",
        "      df_news_click_counts\n",
        "      .join(\n",
        "          calculate_news_click_count(df_news_click_counts_bucketized, time_tag, time_delta),\n",
        "          on=['newsId', 'timeBucket'],\n",
        "          how='inner',\n",
        "      )\n",
        "  )\n",
        "\n",
        "df_news_click_counts = (\n",
        "    df_news_click_counts\n",
        "    .select(\n",
        "        F.column('newsId'),\n",
        "        F.column('time'),\n",
        "        *news_click_counts_column,\n",
        "    )\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxuhe0qJ9YGl",
        "colab_type": "text"
      },
      "source": [
        "# Write files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zsj11shrbEAk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_news_click_counts = (\n",
        "    df_news_click_counts\n",
        "    .repartition(F.column('newsId'))\n",
        "    .sortWithinPartitions(\n",
        "        F.column('time'),\n",
        "        F.column('newsId'),\n",
        "    )\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CqxbFDR2PZy",
        "colab_type": "code",
        "outputId": "363a47b2-c308-48ae-eaf4-918a5f316602",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "df_news_click_counts.write.json(os.path.join(DATA_PATH, 'news_click_counts'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 128 ms, sys: 24.6 ms, total: 152 ms\n",
            "Wall time: 11min 39s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvPKY1Zu2-VR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(os.path.join(DATA_PATH, 'schema', 'news_click_counts.json'), 'w+') as file:\n",
        "  json.dump(df_news_click_counts.schema.jsonValue(), file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLEyG1ODkL2N",
        "colab_type": "code",
        "outputId": "e56c3fac-854e-4741-e12d-e3f3ce45f82d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df_news_click_counts.count()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13630336"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    }
  ]
}