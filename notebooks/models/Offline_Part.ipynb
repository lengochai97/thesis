{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Offline Part.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "LSv4Kukd8FAJ",
        "7vkU69KJShzA",
        "BRugHC8KBbaa",
        "Bs7D4CuzCBfN",
        "qy-THxVECgRi",
        "c1ZW3fHQC2z7",
        "EXpPIgpwErys",
        "2zu3OSg7ExZ5",
        "KVWn3Wj-E8UW"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lengochai97/thesis/blob/master/notebooks/models/Offline_Part.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTCmNOT-hob_",
        "colab_type": "text"
      },
      "source": [
        "# First things first"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VS0bRVS-UCh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q tensorflow==1.13.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lh6dXbv8_8xs",
        "colab": {}
      },
      "source": [
        "import google.colab.drive\n",
        "\n",
        "google.colab.drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cuNXe_Ahx9n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# tf.enable_eager_execution()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YD_FtZr1inz7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnJa4cNKhGeG",
        "colab_type": "text"
      },
      "source": [
        "# Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93Xy9oUIMeiM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_PATH = '/content/gdrive/My Drive/dataset/adressa/one_week'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbvnJRcV1yi0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features = {\n",
        "    'eventId': tf.FixedLenFeature([], tf.int64),\n",
        "    'clickLabel': tf.FixedLenFeature([], tf.int64),\n",
        "    'userActiveness': tf.FixedLenFeature([], tf.float32),\n",
        "    'categoryVector': tf.FixedLenFeature([30], tf.float32),\n",
        "    'newsClickCountVector': tf.FixedLenFeature([4], tf.float32),\n",
        "    'contextVector': tf.FixedLenFeature([32], tf.float32),\n",
        "    'userHistoryVector': tf.FixedLenFeature([30], tf.float32),\n",
        "    'userProfileVector': tf.FixedLenFeature([120], tf.float32),\n",
        "    'userClickCountVector': tf.FixedLenFeature([4], tf.float32),\n",
        "    'userHistoryVectorNext': tf.FixedLenFeature([30], tf.float32),\n",
        "    'userProfileVectorNext': tf.FixedLenFeature([120], tf.float32),\n",
        "    'userClickCountVectorNext': tf.FixedLenFeature([4], tf.float32),\n",
        "}\n",
        "\n",
        "\n",
        "def parse_example(serialized):\n",
        "  e = tf.io.parse_single_example(serialized, features)\n",
        "  \n",
        "  return {\n",
        "      'event_id': e['eventId'],\n",
        "      \n",
        "      'click_label': e['clickLabel'],\n",
        "      \n",
        "      'user_activeness': e['userActiveness'],\n",
        "      \n",
        "      'news_features': tf.concat([e['categoryVector'], tf.math.log(e['newsClickCountVector'] + 1.)], 0),\n",
        "      \n",
        "      'user_features': tf.concat([e['userProfileVector'], tf.math.log(e['userClickCountVector'] + 1.)], 0),\n",
        "      \n",
        "      'user_features_next': tf.concat([e['userProfileVectorNext'], tf.math.log(e['userClickCountVectorNext'] + 1.)], 0),\n",
        "      \n",
        "      'user_news_features': tf.math.reduce_prod([e['categoryVector'], e['userHistoryVector']], axis=0),\n",
        "      \n",
        "      'user_news_features_next': tf.math.reduce_prod([e['categoryVector'], e['userHistoryVectorNext']], axis=0),\n",
        "      \n",
        "      'context_features': e['contextVector'],\n",
        "  }\n",
        "\n",
        "\n",
        "def parse_inputs_targets(serialized):\n",
        "  e = tf.io.parse_single_example(serialized, features)\n",
        "  \n",
        "  inputs = {\n",
        "      'news_features': tf.concat([e['categoryVector'], tf.math.log(e['newsClickCountVector'] + 1.)], 0),\n",
        "      \n",
        "      'user_features': tf.concat([e['userProfileVector'], tf.math.log(e['userClickCountVector'] + 1.)], 0),\n",
        "      \n",
        "      'user_news_features': tf.math.reduce_prod([e['categoryVector'], e['userHistoryVector']], axis=0),\n",
        "      \n",
        "      'context_features': e['contextVector'],\n",
        "  }\n",
        "  \n",
        "  targets = e['clickLabel']\n",
        "  \n",
        "  return inputs, targets\n",
        "\n",
        "def parse_inputs_targets_user_activeness(serialized):\n",
        "  e = tf.io.parse_single_example(serialized, features)\n",
        "  \n",
        "  inputs = {\n",
        "      'news_features': tf.concat([e['categoryVector'], tf.math.log(e['newsClickCountVector'] + 1.)], 0),\n",
        "      \n",
        "      'user_features': tf.concat([e['userProfileVector'], tf.math.log(e['userClickCountVector'] + 1.)], 0),\n",
        "      \n",
        "      'user_news_features': tf.math.reduce_prod([e['categoryVector'], e['userHistoryVector']], axis=0),\n",
        "      \n",
        "      'context_features': e['contextVector'],\n",
        "  }\n",
        "  \n",
        "  user_activeness_coef = tf.constant(.05, tf.float32)\n",
        "  \n",
        "  targets = tf.dtypes.cast(e['clickLabel'], tf.float32) + user_activeness_coef * e['userActiveness']\n",
        "  \n",
        "  return inputs, targets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGMtPviW5-Aa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_dataset_train(filepaths, batch_size, epochs):\n",
        "  dataset = tf.data.TFRecordDataset(filepaths, 'GZIP')\n",
        "  \n",
        "  dataset = (\n",
        "      dataset\n",
        "      .map(parse_inputs_targets)\n",
        "      .batch(batch_size)\n",
        "      .repeat(epochs)\n",
        "      .prefetch(1)\n",
        "  )\n",
        "  \n",
        "  return dataset\n",
        "\n",
        "def build_dataset_train_user_activeness(filepaths, batch_size, epochs):\n",
        "  dataset = tf.data.TFRecordDataset(filepaths, 'GZIP')\n",
        "  \n",
        "  dataset = (\n",
        "      dataset\n",
        "      .map(parse_inputs_targets_user_activeness)\n",
        "      .batch(batch_size)\n",
        "      .repeat(epochs)\n",
        "      .prefetch(1)\n",
        "  )\n",
        "  \n",
        "  return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkFv5UEoIzpw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def flatten_batch(batch):\n",
        "#   return {\n",
        "#       'event_id': tf.reshape(batch['event_id'], [-1]),\n",
        "#       'click_label': tf.reshape(batch['click_label'], [-1]),\n",
        "#       'user_activeness': tf.reshape(batch['user_activeness'], [-1]),\n",
        "#       'news_features': tf.reshape(batch['news_features'], [-1, batch['news_features'].shape[2]]),\n",
        "#       'user_features': tf.reshape(batch['user_features'], [-1, batch['user_features'].shape[2]]),\n",
        "#       'user_features_next': tf.reshape(batch['user_features_next'], [-1, batch['user_features_next'].shape[2]]),\n",
        "#       'user_news_features': tf.reshape(batch['user_news_features'], [-1, batch['user_news_features'].shape[2]]),\n",
        "#       'user_news_features_next': tf.reshape(batch['user_news_features_next'], [-1, batch['user_news_features_next'].shape[2]]),\n",
        "#       'context_features': tf.reshape(batch['context_features'], [-1, batch['context_features'].shape[2]]),\n",
        "#   }\n",
        "\n",
        "# def build_dataset_test(filepaths, n_candidates, batch_size_update):\n",
        "#   dataset = tf.data.TFRecordDataset(filepaths, 'GZIP')\n",
        "  \n",
        "#   dataset = (\n",
        "#       dataset\n",
        "#       .map(parse_example)\n",
        "#       .apply(\n",
        "#           tf.data.experimental.group_by_window(\n",
        "#               key_func=lambda e: e['event_id'],\n",
        "#               reduce_func=lambda k, ds: ds.repeat(n_candidates).batch(n_candidates).take(1),\n",
        "#               window_size=n_candidates,\n",
        "#           )\n",
        "#       )\n",
        "#       .batch(batch_size_update)\n",
        "#       .map(flatten_batch)\n",
        "#       .prefetch(1)\n",
        "#   )\n",
        "  \n",
        "#   return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NMRNzTZ_kml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def get_recommendation_indices(predictions, n_candidates, k_recommendations):\n",
        "#   n_events = predictions.shape[0] // n_candidates\n",
        "  \n",
        "#   return np.reshape(\n",
        "#       (np.argsort(np.reshape(predictions, (n_events, n_candidates)), axis=1)[:, -k_recommendations:]\n",
        "#       + np.reshape(np.arange(n_events) * n_candidates, (n_events, 1))),\n",
        "#       (n_events * k_recommendations, 1)\n",
        "#   )\n",
        "\n",
        "\n",
        "# def get_recommendation_data(batch, indices):\n",
        "#   return {k: tf.gather_nd(v, indices) for k, v in batch.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "C6rTLodZ_8yc",
        "colab": {}
      },
      "source": [
        "# Dataset details\n",
        "\n",
        "n_samples_train = 12915691\n",
        "# n_samples_test = 1796331\n",
        "\n",
        "n_events_train = 1076343\n",
        "# n_events_test = 149824\n",
        "\n",
        "n_candidates = 12\n",
        "k_recommendations = 5\n",
        "\n",
        "# Fit parameters\n",
        "\n",
        "batch_size = 1024\n",
        "epochs = 1\n",
        "steps_per_epoch = int(np.ceil(n_samples_train / batch_size))\n",
        "\n",
        "# Evaluate parameters\n",
        "\n",
        "# batch_size_update = 200 # Update networks after every `batch_size_update` requests"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ibegCe5s_8yj",
        "colab": {}
      },
      "source": [
        "filepaths = sorted(glob.glob(os.path.join(DATA_PATH, 'tfrecords', 'train', '*')))\n",
        "\n",
        "dataset_train = build_dataset_train(filepaths, batch_size, epochs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFmYS4Ku---n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_train_user_activeness = build_dataset_train_user_activeness(filepaths, batch_size, epochs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6fN9P7Sn_8yo",
        "colab": {}
      },
      "source": [
        "# filepaths = sorted(glob.glob(os.path.join(DATA_PATH, 'tfrecords', 'test', '*')))\n",
        "\n",
        "# dataset_test = build_dataset_test(filepaths, n_candidates, batch_size_update)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLBRvjc4uzwc",
        "colab_type": "text"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmdghKYjwMF0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.activations import relu, sigmoid\n",
        "from tensorflow.keras.layers import Activation, Add, Concatenate, Dense, Dot, Input, Lambda, Subtract\n",
        "from tensorflow.keras.losses import BinaryCrossentropy, MeanSquaredError\n",
        "from tensorflow.keras.metrics import binary_accuracy\n",
        "from tensorflow.keras.models import load_model, Model\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFMZNwuTu-FZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_info = (\n",
        "    ('news_features', (34,)),\n",
        "    ('user_features', (124,)),\n",
        "    ('user_news_features', (30,)),\n",
        "    ('context_features', (32,)),\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-yGI9c-Osij",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def evaluate(eval_id, eval_click, eval_prediction, k_recommendations):\n",
        "#   df = pd.DataFrame({\n",
        "#       'id': eval_id.numpy(),\n",
        "#       'click': eval_click.numpy(),\n",
        "#       'prediction': eval_prediction.numpy(),\n",
        "#   })\n",
        "  \n",
        "#   df['rank'] = df.groupby('id')['prediction'].rank(method='max', ascending=False)\n",
        "  \n",
        "#   patk = df[(df['click'] == 1) & (df['rank'] <= k_recommendations)].shape[0] / (df[(df['click'] == 1)].shape[0] * k_recommendations)\n",
        "  \n",
        "#   ndcg = df[(df['click'] == 1)]['rank'].map(lambda r: 1 / np.log2(r + 1) if r <= k_recommendations else 0).mean()\n",
        "  \n",
        "#   return patk, ndcg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uGTO4_ZwBJu",
        "colab_type": "text"
      },
      "source": [
        "## 1. Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eaFgFaou5Uw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_lr(input_info):\n",
        "  inputs = [Input(shape=shape, name=name) for name, shape in input_info]\n",
        "  \n",
        "  inputs_concat = Concatenate()(inputs)\n",
        "  \n",
        "  outputs = Dense(1, activation=sigmoid)(inputs_concat)\n",
        "  \n",
        "  model = Model(inputs=inputs, outputs=outputs)  \n",
        "  model.compile(RMSprop(), loss=BinaryCrossentropy(), metrics=[binary_accuracy])\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26FsfrOt_xxD",
        "colab_type": "text"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SF0foVe_1IrZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = build_lr(input_info)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DxA33_Y3Z-X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr.fit(dataset_train, batch_size=batch_size, epochs=epochs, steps_per_epoch=steps_per_epoch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3TTX8G_7Ols",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr.save(os.path.join(DATA_PATH, 'model', 'lr_weights.h5'), overwrite=True, include_optimizer=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSv4Kukd8FAJ",
        "colab_type": "text"
      },
      "source": [
        "### Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tleVCAT8HRg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# lr_test = build_lr(input_info)\n",
        "# lr_test.load_weights(os.path.join(DATA_PATH, 'model', 'lr_weights.h5'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSSYsdSg_pD_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# eval_id = tf.constant([], dtype=tf.int64)\n",
        "# eval_click = tf.constant([], dtype=tf.int64)\n",
        "# eval_prediction = tf.constant([], dtype=tf.float32)\n",
        "\n",
        "# for batch in tqdm.tqdm(dataset_test, total=np.ceil(n_events_test / batch_size_update)):\n",
        "#   predictions = lr_test.predict(batch, steps=1)\n",
        "  \n",
        "#   recommendation_indices = get_recommendation_indices(predictions, n_candidates, k_recommendations)\n",
        "#   recommendation_data = get_recommendation_data(batch, recommendation_indices)\n",
        "  \n",
        "#   eval_id = tf.concat([eval_id, batch['event_id']], 0)\n",
        "#   eval_click = tf.concat([eval_click, batch['click_label']], 0)\n",
        "#   eval_prediction = tf.concat([eval_prediction, predictions.flatten()], 0)\n",
        "  \n",
        "#   batch_size = (predictions.shape[0] // n_candidates * k_recommendations)\n",
        "  \n",
        "  \n",
        "#   lr_test.fit(recommendation_data, recommendation_data['click_label'], verbose=0, batch_size=batch_size, steps_per_epoch=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wMKC6He_rKF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# evaluate(eval_id, eval_click, eval_prediction, k_recommendations)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yphRbEvAgV2",
        "colab_type": "text"
      },
      "source": [
        "## 2. Factorization Machines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ydx1h80tAivH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_fm(input_info, k_latent):\n",
        "  inputs = [Input(shape=shape, name=name) for name, shape in input_info]\n",
        "  \n",
        "  inputs_concat = Concatenate()(inputs)\n",
        "  \n",
        "  inputs_flat = [Lambda(lambda x: x[:, i:i+1])(inputs_concat) for i in range(inputs_concat.shape[1].value)]\n",
        "  \n",
        "  biases = [Dense(1)(x) for x in inputs_flat]\n",
        "  \n",
        "  factors = [Dense(k_latent)(x) for x in inputs_flat]\n",
        "  \n",
        "  s = Add()(factors)\n",
        "  \n",
        "  diffs = [Subtract()([s, x]) for x in factors]\n",
        "  \n",
        "  dots = [Dot(axes=1)([d, x]) for d, x in zip(diffs, factors)]\n",
        "  \n",
        "  outputs = Add()(dots + biases)\n",
        "  outputs = Dense(1, activation=sigmoid)(outputs)\n",
        "\n",
        "  model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "  model.compile(Adam(), loss=BinaryCrossentropy(), metrics=[binary_accuracy])\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbJWgzj6SgJ3",
        "colab_type": "text"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2rrHTySCzGA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fm = build_fm(input_info, k_latent=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wyq_RVRDa0S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fm.fit(dataset_train, batch_size=batch_size, epochs=epochs, steps_per_epoch=steps_per_epoch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "div7d9sw7tVr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fm.save_weights(os.path.join(DATA_PATH, 'model', 'fm_weights.h5'), overwrite=True, include_optimizer=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vkU69KJShzA",
        "colab_type": "text"
      },
      "source": [
        "### Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syYeLPAx6D-T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fm_test = build_fm(input_info, k_latent=2)\n",
        "# fm_test.load_weights(os.path.join(DATA_PATH, 'model', 'fm_weights.h5'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gc9fhYjSw0E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# eval_id = tf.constant([], dtype=tf.int64)\n",
        "# eval_click = tf.constant([], dtype=tf.int64)\n",
        "# eval_prediction = tf.constant([], dtype=tf.float32)\n",
        "\n",
        "# for batch in tqdm.tqdm(dataset_test, total=np.ceil(n_events_test / batch_size_update)):\n",
        "#   predictions = fm_test.predict(batch, steps=1)\n",
        "  \n",
        "#   recommendation_indices = get_recommendation_indices(predictions, n_candidates, k_recommendations)\n",
        "#   recommendation_data = get_recommendation_data(batch, recommendation_indices)\n",
        "  \n",
        "#   eval_id = tf.concat([eval_id, batch['event_id']], 0)\n",
        "#   eval_click = tf.concat([eval_click, batch['click_label']], 0)\n",
        "#   eval_prediction = tf.concat([eval_prediction, predictions.flatten()], 0)\n",
        "  \n",
        "#   batch_size = (predictions.shape[0] // n_candidates * k_recommendations)\n",
        "  \n",
        "#   fm_test.fit(recommendation_data, recommendation_data['click_label'], verbose=0, batch_size=batch_size, steps_per_epoch=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dF448CVUXYUh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# evaluate(eval_id, eval_click, eval_prediction, k_recommendations)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Kt2K9OF7GlY",
        "colab_type": "text"
      },
      "source": [
        "## 3. Wide & Deep"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NZecxzb7LnE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_wd(input_info):\n",
        "  inputs = [Input(shape=shape, name=name) for name, shape in input_info]\n",
        "  \n",
        "  inputs_concat = Concatenate()(inputs)\n",
        "  \n",
        "  wide = Concatenate()(inputs)\n",
        "  \n",
        "  deep = Dense(256, activation=relu)(inputs_concat)\n",
        "  deep = Dense(128, activation=relu)(deep)\n",
        "  \n",
        "  wide_deep = Concatenate()([wide, deep])\n",
        "  \n",
        "  outputs = Dense(1, activation=sigmoid)(wide_deep)\n",
        "  \n",
        "  model = Model(inputs=inputs, outputs=outputs)\n",
        "  \n",
        "  model.compile(RMSprop(), loss=BinaryCrossentropy(), metrics=[binary_accuracy])\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbGIwfgdBMGp",
        "colab_type": "text"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uu9LcfG0_UXk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wd = build_wd(input_info)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BttGFwVw_YUp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wd.fit(dataset_train, batch_size=batch_size, epochs=epochs, steps_per_epoch=steps_per_epoch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yPJP8pI_ZkV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wd.save(os.path.join(DATA_PATH, 'model', 'wd_weights.h5'), overwrite=True, include_optimizer=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRugHC8KBbaa",
        "colab_type": "text"
      },
      "source": [
        "### Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "D2_JqbxcRPot",
        "colab": {}
      },
      "source": [
        "# wd_test = build_wd(input_info)\n",
        "# wd_test.load_weights(os.path.join(DATA_PATH, 'model', 'wd_weights.h5'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wFsd8Kb2RPo3",
        "colab": {}
      },
      "source": [
        "# eval_id = tf.constant([], dtype=tf.int64)\n",
        "# eval_click = tf.constant([], dtype=tf.int64)\n",
        "# eval_prediction = tf.constant([], dtype=tf.float32)\n",
        "\n",
        "# for batch in tqdm.tqdm(dataset_test, total=np.ceil(n_events_test / batch_size_update)):\n",
        "#   predictions = wd_test.predict(batch, steps=1)\n",
        "  \n",
        "#   recommendation_indices = get_recommendation_indices(predictions, n_candidates, k_recommendations)\n",
        "#   recommendation_data = get_recommendation_data(batch, recommendation_indices)\n",
        "  \n",
        "#   eval_id = tf.concat([eval_id, batch['event_id']], 0)\n",
        "#   eval_click = tf.concat([eval_click, batch['click_label']], 0)\n",
        "#   eval_prediction = tf.concat([eval_prediction, predictions.flatten()], 0)\n",
        "  \n",
        "#   batch_size = (predictions.shape[0] // n_candidates * k_recommendations)\n",
        "  \n",
        "#   wd_test.fit(recommendation_data, recommendation_data['click_label'], verbose=0, batch_size=batch_size, steps_per_epoch=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmWWW_sRerpJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# evaluate(eval_id, eval_click, eval_prediction, k_recommendations)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqP5EnqwU3vb",
        "colab_type": "text"
      },
      "source": [
        "## 4. DQN without future reward"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sRWTMrsSjzi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_dqn(input_info, state_indices):\n",
        "  inputs = [Input(shape=shape, name=name) for name, shape in input_info]\n",
        "  \n",
        "  inputs_concat = Concatenate()(inputs)\n",
        "  \n",
        "  value = Concatenate()([inputs[i] for i in state_indices])\n",
        "  value = Dense(256, activation=relu)(value)\n",
        "  value = Dense(128, activation=relu)(value)\n",
        "  value = Dense(1)(value)\n",
        "  \n",
        "  advantage = Dense(256, activation=relu)(inputs_concat)\n",
        "  advantage = Dense(128, activation=relu)(advantage)\n",
        "  advantage = Dense(1)(advantage)\n",
        "\n",
        "  value_advantage = Concatenate()([value, advantage])\n",
        "  \n",
        "  outputs = Dense(1)(value_advantage)\n",
        "\n",
        "  model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "  model.compile(Adam(), loss=MeanSquaredError())\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEH2ne4EBsac",
        "colab_type": "text"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dTU6TXRBtY2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dqn = build_dqn(input_info, [1, 3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xo9jQS3BuR_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dqn.fit(dataset_train, batch_size=batch_size, epochs=epochs, steps_per_epoch=steps_per_epoch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wq2cZMehBxjs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dqn.save_weights(os.path.join(DATA_PATH, 'model', 'dqn_weights.h5'), overwrite=True, include_optimizer=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "844dxy_2B2nF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dqnu = build_dqn(input_info, [1, 3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyQ8PpaiB5AC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dqnu.fit(dataset_train, batch_size=batch_size, epochs=epochs, steps_per_epoch=steps_per_epoch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Um-lb8JEB6sq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dqnu.save_weights(os.path.join(DATA_PATH, 'model', 'dqnu_weights.h5'), overwrite=True, include_optimizer=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bs7D4CuzCBfN",
        "colab_type": "text"
      },
      "source": [
        "### Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BT9Z6NF1CEcS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dqn_test = build_dqn(input_info, [1, 3])\n",
        "# dqn_test.load_weights(os.path.join(DATA_PATH, 'model', 'dqn_weights.h5'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzSQSdX8CHzS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# eval_id = tf.constant([], dtype=tf.int64)\n",
        "# eval_click = tf.constant([], dtype=tf.int64)\n",
        "# eval_prediction = tf.constant([], dtype=tf.float32)\n",
        "\n",
        "# for batch in tqdm.tqdm(dataset_test, total=np.ceil(n_events_test / batch_size_update)):\n",
        "#   predictions = dqn_test.predict(batch, steps=1)\n",
        "  \n",
        "#   recommendation_indices = get_recommendation_indices(predictions, n_candidates, k_recommendations)\n",
        "#   recommendation_data = get_recommendation_data(batch, recommendation_indices)\n",
        "  \n",
        "#   eval_id = tf.concat([eval_id, batch['event_id']], 0)\n",
        "#   eval_click = tf.concat([eval_click, batch['click_label']], 0)\n",
        "#   eval_prediction = tf.concat([eval_prediction, predictions.flatten()], 0)\n",
        "  \n",
        "#   batch_size = (predictions.shape[0] // n_candidates * k_recommendations)\n",
        "  \n",
        "#   dqn_test.fit(recommendation_data, recommendation_data['click_label'], verbose=0, batch_size=batch_size, steps_per_epoch=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqZoiqeBCMzD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# evaluate(eval_id, eval_click, eval_prediction, k_recommendations)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qy-THxVECgRi",
        "colab_type": "text"
      },
      "source": [
        "## 5. DDQN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "De-PnhYUKv8a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# class DDQN(object):\n",
        "#   def __init__(\n",
        "#       self, input_info, state_indices, weights_path,\n",
        "#       target_update_steps, major_update_steps,\n",
        "#       future_reward_discount, user_activeness_coef,\n",
        "#       epsilon, explore_coef, exploit_coef,\n",
        "#   ):\n",
        "    \n",
        "#     self.dqn = self._build_dqn(input_info, state_indices)\n",
        "#     self.dqn.load_weights(weights_path)\n",
        "    \n",
        "#     self.target_dqn = self._build_dqn(input_info, state_indices)\n",
        "#     self.target_dqn.load_weights(weights_path)\n",
        "    \n",
        "#     self.explore_dqn = self._build_dqn(input_info, state_indices)\n",
        "#     self.explore_dqn.load_weights(weights_path)\n",
        "    \n",
        "#     self.target_update_steps = target_update_steps\n",
        "#     self.major_update_steps = major_update_steps\n",
        "    \n",
        "#     self.future_reward_discount = tf.constant(future_reward_discount, tf.float32)\n",
        "#     self.user_activeness_coef = tf.constant(user_activeness_coef, tf.float32)\n",
        "    \n",
        "#     self.epsilon = epsilon\n",
        "#     self.explore_coef = explore_coef\n",
        "#     self.exploit_coef = exploit_coef\n",
        "    \n",
        "#     self.memory = []\n",
        "    \n",
        "#   def _build_dqn(self, input_info, state_indices):\n",
        "#     inputs = [Input(shape=shape, name=name) for name, shape in input_info]\n",
        "\n",
        "#     inputs_concat = Concatenate()(inputs)\n",
        "\n",
        "#     value = Concatenate()([inputs[i] for i in state_indices])\n",
        "#     value = Dense(256, activation=relu)(value)\n",
        "#     value = Dense(128, activation=relu)(value)\n",
        "#     value = Dense(1)(value)\n",
        "\n",
        "#     advantage = Dense(256, activation=relu)(inputs_concat)\n",
        "#     advantage = Dense(128, activation=relu)(advantage)\n",
        "#     advantage = Dense(1)(advantage)\n",
        "\n",
        "#     value_advantage = Concatenate()([value, advantage])\n",
        "\n",
        "#     outputs = Dense(1)(value_advantage)\n",
        "\n",
        "#     model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "#     model.compile(Adam(), loss=MeanSquaredError())\n",
        "\n",
        "#     return model\n",
        "  \n",
        "#   def _expand_news_data(self, ts, n, k):\n",
        "#     return tf.reshape(tf.broadcast_to(tf.reshape(ts, [n, k, ts.shape[1]]), [n, k*k, ts.shape[1]]), [n*k*k, ts.shape[1]])\n",
        "  \n",
        "#   def _expand_user_data(self, ts, n, k):\n",
        "#     return tf.reshape(tf.broadcast_to(ts, [n*k, ts.shape[1]*k]), [n*k*k, ts.shape[1]])\n",
        "  \n",
        "#   def _update_target_dqn(self):\n",
        "#     self.target_dqn.set_weights(self.dqn.get_weights())\n",
        "    \n",
        "#   def _interleave(self, list0, list1):\n",
        "#     lists = [list0, list1]\n",
        "\n",
        "#     interleaved = []\n",
        "\n",
        "#     for i in np.random.randint(2, size=len(list0)):\n",
        "#       item = lists[i].pop()\n",
        "#       lists[1-i].remove(item)\n",
        "#       interleaved.append(item)\n",
        "\n",
        "#     return interleaved\n",
        "  \n",
        "#   def add_future_rewards_user_activeness(self, batch, k):\n",
        "#     n = batch['click_label'].shape[0].value // k\n",
        "    \n",
        "#     inputs = {\n",
        "#         'news_features': self._expand_news_data(batch['news_features'], n, k),\n",
        "#         'user_features': self._expand_user_data(batch['user_features_next'], n, k),\n",
        "#         'user_news_features': self._expand_news_data(batch['user_news_features_next'], n, k),\n",
        "#         'context_features': self._expand_news_data(batch['context_features'], n, k),\n",
        "#     }\n",
        "\n",
        "#     target_actions = self.target_dqn.predict(inputs, steps=1).reshape([-1, k]).argmax(1)\n",
        "#     target_actions = np.reshape(np.reshape(np.arange(n) * k, [-1, 1]) + target_actions.reshape([n, k]), [-1, 1])\n",
        "\n",
        "#     inputs = {\n",
        "#         'news_features': tf.gather_nd(batch['news_features'], target_actions),\n",
        "#         'user_features': batch['user_features_next'],\n",
        "#         'user_news_features': tf.gather_nd(batch['user_news_features_next'], target_actions),\n",
        "#         'context_features': tf.gather_nd(batch['context_features'], target_actions),\n",
        "#     }\n",
        "\n",
        "#     future_rewards = self.dqn.predict(inputs, steps=1).flatten()\n",
        "\n",
        "#     rewards = (\n",
        "#         tf.dtypes.cast(batch['click_label'], tf.float32)\n",
        "#         + self.future_reward_discount * tf.convert_to_tensor(future_rewards, tf.float32)\n",
        "#         + self.user_activeness_coef * batch['user_activeness']\n",
        "#     )\n",
        "    \n",
        "#     batch['reward'] = rewards\n",
        "    \n",
        "#     return batch\n",
        "  \n",
        "#   def predict(self, batch):\n",
        "#     return self.dqn.predict(batch, steps=1)\n",
        "  \n",
        "#   def predict_eg(self, batch):\n",
        "#     batch_size = batch['click_label'].shape[0].value\n",
        "    \n",
        "#     if np.random.rand() < self.epsilon:\n",
        "#       return np.random.rand(batch_size, 1)\n",
        "#     else:\n",
        "#       return self.predict(batch)\n",
        "    \n",
        "#   def predict_dbgd(self, batch):\n",
        "#     self.explore_dqn.set_weights([np.random.uniform(-1, 1) * self.explore_coef * w for w in self.dqn.get_weights()])\n",
        "      \n",
        "#     indices_0 = self.dqn.predict(batch, steps=1).flatten().argsort().tolist()\n",
        "#     indices_1 = self.explore_dqn.predict(batch, steps=1).flatten().argsort().tolist()\n",
        "\n",
        "#     indices = self._interleave(indices_0, indices_1)\n",
        "\n",
        "#     predictions = np.zeros(len(indices))\n",
        "#     predictions[indices] = 1. / np.arange(1, len(indices) + 1)\n",
        "\n",
        "#     return predictions\n",
        "    \n",
        "#   def fit_batch(self, batch, k_recommendations):\n",
        "#     batch = tf.data.Dataset.from_tensor_slices(batch).batch(self.target_update_steps * k_recommendations)\n",
        "    \n",
        "#     for mini_batch in batch:\n",
        "#       batch_size = mini_batch['reward'].shape[0].value\n",
        "#       self.dqn.fit(mini_batch, mini_batch['reward'], verbose=0, batch_size=batch_size, steps_per_epoch=1)\n",
        "#       self._update_target_dqn()\n",
        "      \n",
        "#   def minor_update(self, batch, k_recommendations):\n",
        "#     self._update_explore_dqn(batch, k_recommendations)\n",
        "    \n",
        "#     self.memory.append(batch)\n",
        "    \n",
        "#     if len(self.memory) >= self.major_update_steps:\n",
        "#       self._major_update(k_recommendations)\n",
        "      \n",
        "#       self.memory = []\n",
        "      \n",
        "#   def _major_update(self, k_recommendations):\n",
        "#     batch_size = self.target_update_steps * k_recommendations\n",
        "    \n",
        "#     memory = tf.data.Dataset.from_tensor_slices(self.memory[0])\n",
        "#     for batch in self.memory[1:]:\n",
        "#       memory = memory.concatenate(tf.data.Dataset.from_tensor_slices(batch))\n",
        "#     memory = memory.batch(batch_size)\n",
        "    \n",
        "#     for batch in memory:\n",
        "#       self.dqn.fit(batch, batch['reward'], verbose=0, batch_size=batch_size, steps_per_epoch=1)\n",
        "#       self._update_target_dqn()\n",
        "      \n",
        "#   def _update_explore_dqn(self, batch, k_recommendations):\n",
        "#     predictions_0 = self.dqn.predict(batch, steps=1)\n",
        "#     predictions_1 = self.explore_dqn.predict(batch, steps=1)\n",
        "    \n",
        "#     click_labels = batch['click_label']\n",
        "    \n",
        "#     ndcg_0 = self._calculate_ndcg(predictions_0, click_labels, k_recommendations)\n",
        "#     ndcg_1 = self._calculate_ndcg(predictions_1, click_labels, k_recommendations)\n",
        "    \n",
        "#     if ndcg_0 < ndcg_1:\n",
        "#       self.dqn.set_weights([w0 + self.exploit_coef * w1 for (w0, w1) in zip(self.dqn.get_weights(), self.explore_dqn.get_weights())])\n",
        "      \n",
        "#   def _calculate_ndcg(self, predictions, click_labels, k_recommendations):\n",
        "#     # Convert tensor to numpy array\n",
        "#     click_labels = click_labels.numpy().flatten()\n",
        "    \n",
        "#     n_events = click_labels.shape[0] // k_recommendations\n",
        "    \n",
        "#     indices = (\n",
        "#         np.argsort(np.reshape(predictions, [n_events, k_recommendations]), 1)\n",
        "#         + np.reshape(np.arange(n_events) * k_recommendations, [-1, 1])\n",
        "#     )\n",
        "    \n",
        "#     indices = indices.flatten()\n",
        "    \n",
        "#     discount = np.zeros(indices.shape)\n",
        "#     discount[indices] = np.tile(np.arange(2, k_recommendations + 2), n_events)\n",
        "    \n",
        "#     ndcg = click_labels / np.log2(discount)\n",
        "    \n",
        "#     return ndcg.mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1ZW3fHQC2z7",
        "colab_type": "text"
      },
      "source": [
        "### DDQN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pH-cXLEgV4wN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# weights_path = os.path.join(DATA_PATH, 'model', 'dqn_weights.h5')\n",
        "\n",
        "# ddqn = DDQN(\n",
        "#     input_info, [1, 3], weights_path,\n",
        "#     target_update_steps=50, major_update_steps=2,\n",
        "#     future_reward_discount=0.1, user_activeness_coef=0,\n",
        "#     epsilon=0, explore_coef=0, exploit_coef=0,\n",
        "# )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUJn-RdxEJQX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# eval_id = tf.constant([], dtype=tf.int64)\n",
        "# eval_click = tf.constant([], dtype=tf.int64)\n",
        "# eval_prediction = tf.constant([], dtype=tf.float32)\n",
        "\n",
        "# for batch in tqdm.tqdm(dataset_test, total=np.ceil(n_events_test / batch_size_update)):\n",
        "#   batch = ddqn.add_future_rewards_user_activeness(batch, n_candidates)\n",
        "  \n",
        "#   predictions = ddqn.predict(batch)\n",
        "  \n",
        "#   recommendation_indices = get_recommendation_indices(predictions, n_candidates, k_recommendations)\n",
        "#   recommendation_data = get_recommendation_data(batch, recommendation_indices)\n",
        "  \n",
        "#   eval_id = tf.concat([eval_id, batch['event_id']], 0)\n",
        "#   eval_click = tf.concat([eval_click, batch['click_label']], 0)\n",
        "#   eval_prediction = tf.concat([eval_prediction, predictions.flatten()], 0)\n",
        "  \n",
        "#   ddqn.fit_batch(recommendation_data, k_recommendations)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keGIGUPAEdSH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# evaluate(eval_id, eval_click, eval_prediction, k_recommendations)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXpPIgpwErys",
        "colab_type": "text"
      },
      "source": [
        "### DDQN + U"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaMIvFZREtPL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# weights_path = os.path.join(DATA_PATH, 'model', 'dqnu_weights.h5')\n",
        "\n",
        "# ddqn = DDQN(\n",
        "#     input_info, [1, 3], weights_path,\n",
        "#     target_update_steps=50, major_update_steps=2,\n",
        "#     future_reward_discount=0.1, user_activeness_coef=0.05,\n",
        "#     epsilon=0, explore_coef=0, exploit_coef=0,\n",
        "# )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZaSuwqVEvNN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# eval_id = tf.constant([], dtype=tf.int64)\n",
        "# eval_click = tf.constant([], dtype=tf.int64)\n",
        "# eval_prediction = tf.constant([], dtype=tf.float32)\n",
        "\n",
        "# for batch in tqdm.tqdm(dataset_test, total=np.ceil(n_events_test / batch_size_update)):\n",
        "#   batch = ddqn.add_future_rewards_user_activeness(batch, n_candidates)\n",
        "  \n",
        "#   predictions = ddqn.predict(batch)\n",
        "  \n",
        "#   recommendation_indices = get_recommendation_indices(predictions, n_candidates, k_recommendations)\n",
        "#   recommendation_data = get_recommendation_data(batch, recommendation_indices)\n",
        "  \n",
        "#   eval_id = tf.concat([eval_id, batch['event_id']], 0)\n",
        "#   eval_click = tf.concat([eval_click, batch['click_label']], 0)\n",
        "#   eval_prediction = tf.concat([eval_prediction, predictions.flatten()], 0)\n",
        "  \n",
        "#   ddqn.fit_batch(recommendation_data, k_recommendations)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjkSADmtEwfc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# evaluate(eval_id, eval_click, eval_prediction, k_recommendations)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zu3OSg7ExZ5",
        "colab_type": "text"
      },
      "source": [
        "### DDQN + U + EG"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrxdroI9E2v6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# weights_path = os.path.join(DATA_PATH, 'model', 'dqnu_weights.h5')\n",
        "\n",
        "# ddqn = DDQN(\n",
        "#     input_info, [1, 3], weights_path,\n",
        "#     target_update_steps=50, major_update_steps=2,\n",
        "#     future_reward_discount=0.1, user_activeness_coef=0.05,\n",
        "#     epsilon=0.05, explore_coef=0, exploit_coef=0,\n",
        "# )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkLhyeKZE5lW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# eval_id = tf.constant([], dtype=tf.int64)\n",
        "# eval_click = tf.constant([], dtype=tf.int64)\n",
        "# eval_prediction = tf.constant([], dtype=tf.float32)\n",
        "\n",
        "# for batch in tqdm.tqdm(dataset_test, total=np.ceil(n_events_test / batch_size_update)):\n",
        "#   batch = ddqn.add_future_rewards_user_activeness(batch, n_candidates)\n",
        "  \n",
        "#   predictions = ddqn.predict_eg(batch)\n",
        "  \n",
        "#   recommendation_indices = get_recommendation_indices(predictions, n_candidates, k_recommendations)\n",
        "#   recommendation_data = get_recommendation_data(batch, recommendation_indices)\n",
        "  \n",
        "#   eval_id = tf.concat([eval_id, batch['event_id']], 0)\n",
        "#   eval_click = tf.concat([eval_click, batch['click_label']], 0)\n",
        "#   eval_prediction = tf.concat([eval_prediction, predictions.flatten()], 0)\n",
        "  \n",
        "#   ddqn.fit_batch(recommendation_data, k_recommendations)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGAmPRO-E68U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# evaluate(eval_id, eval_click, eval_prediction, k_recommendations)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVWn3Wj-E8UW",
        "colab_type": "text"
      },
      "source": [
        "### DDQN + U + DBGD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FCwg10VE-yz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# weights_path = os.path.join(DATA_PATH, 'model', 'dqnu_weights.h5')\n",
        "\n",
        "# ddqn = DDQN(\n",
        "#     input_info, [1, 3], weights_path,\n",
        "#     target_update_steps=50, major_update_steps=2,\n",
        "#     future_reward_discount=0.1, user_activeness_coef=0.05,\n",
        "#     epsilon=0, explore_coef=0.1, exploit_coef=0.05,\n",
        "# )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CxgyKU6FAwY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# eval_id = tf.constant([], dtype=tf.int64)\n",
        "# eval_click = tf.constant([], dtype=tf.int64)\n",
        "# eval_prediction = tf.constant([], dtype=tf.float32)\n",
        "\n",
        "# for batch in tqdm.tqdm(dataset_test, total=np.ceil(n_events_test / batch_size_update)):\n",
        "#   batch = ddqn.add_future_rewards_user_activeness(batch, n_candidates)\n",
        "  \n",
        "#   predictions = ddqn.predict_dbgd(batch)\n",
        "  \n",
        "#   recommendation_indices = get_recommendation_indices(predictions, n_candidates, k_recommendations)\n",
        "#   recommendation_data = get_recommendation_data(batch, recommendation_indices)\n",
        "  \n",
        "#   eval_id = tf.concat([eval_id, batch['event_id']], 0)\n",
        "#   eval_click = tf.concat([eval_click, batch['click_label']], 0)\n",
        "#   eval_prediction = tf.concat([eval_prediction, predictions.flatten()], 0)\n",
        "  \n",
        "#   ddqn.minor_update(recommendation_data, k_recommendations)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIQWrs70FCGv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# evaluate(eval_id, eval_click, eval_prediction, k_recommendations)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}