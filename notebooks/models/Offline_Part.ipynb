{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Offline Part.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lengochai97/thesis/blob/master/notebooks/models/Offline_Part.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTCmNOT-hob_",
        "colab_type": "text"
      },
      "source": [
        "# Prepare environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lh6dXbv8_8xs",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "\n",
        "import google.colab.drive\n",
        "\n",
        "google.colab.drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YD_FtZr1inz7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import functools\n",
        "import glob\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnJa4cNKhGeG",
        "colab_type": "text"
      },
      "source": [
        "# Prepare dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93Xy9oUIMeiM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_PATH = '/content/gdrive/My Drive/dataset/adressa/one_week'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TtUKS9L9uPv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features = {\n",
        "    'eventId': tf.io.FixedLenFeature([], tf.int64),\n",
        "    'clickLabel': tf.io.FixedLenFeature([], tf.int64),\n",
        "    'userActiveness': tf.io.FixedLenFeature([], tf.float32),\n",
        "    'categoryVector': tf.io.FixedLenFeature([30], tf.float32),\n",
        "    'newsClickCountVector': tf.io.FixedLenFeature([4], tf.float32),\n",
        "    'contextVector': tf.io.FixedLenFeature([32], tf.float32),\n",
        "    'userHistoryVector': tf.io.FixedLenFeature([30], tf.float32),\n",
        "    'userProfileVector': tf.io.FixedLenFeature([120], tf.float32),\n",
        "    'userClickCountVector': tf.io.FixedLenFeature([4], tf.float32),\n",
        "    'userHistoryVectorNext': tf.io.FixedLenFeature([30], tf.float32),\n",
        "    'userProfileVectorNext': tf.io.FixedLenFeature([120], tf.float32),\n",
        "    'userClickCountVectorNext': tf.io.FixedLenFeature([4], tf.float32),\n",
        "}\n",
        "\n",
        "\n",
        "def parse_example(serialized):\n",
        "  e = tf.io.parse_single_example(serialized, features)\n",
        "  \n",
        "  return {\n",
        "      'event_id': e['eventId'],\n",
        "      \n",
        "      'click_label': e['clickLabel'],\n",
        "      \n",
        "      'user_activeness': e['userActiveness'],\n",
        "      \n",
        "      'news_features': tf.concat([e['categoryVector'], tf.math.log(e['newsClickCountVector'] + 1.)], 0),\n",
        "      \n",
        "      'user_features': tf.concat([e['userProfileVector'], tf.math.log(e['userClickCountVector'] + 1.)], 0),\n",
        "      \n",
        "      'user_features_next': tf.concat([e['userProfileVectorNext'], tf.math.log(e['userClickCountVectorNext'] + 1.)], 0),\n",
        "      \n",
        "      'user_news_features': tf.math.reduce_prod([e['categoryVector'], e['userHistoryVector']], axis=0),\n",
        "      \n",
        "      'user_news_features_next': tf.math.reduce_prod([e['categoryVector'], e['userHistoryVectorNext']], axis=0),\n",
        "      \n",
        "      'context_features': e['contextVector'],\n",
        "  }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbvnJRcV1yi0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parse_inputs_targets(serialized):\n",
        "  e = tf.io.parse_single_example(serialized, features)\n",
        "  \n",
        "  inputs = {\n",
        "      'news_features': tf.concat([e['categoryVector'], tf.math.log(e['newsClickCountVector'] + 1.)], 0),\n",
        "      \n",
        "      'user_features': tf.concat([e['userProfileVector'], tf.math.log(e['userClickCountVector'] + 1.)], 0),\n",
        "      \n",
        "      'user_news_features': tf.math.reduce_prod([e['categoryVector'], e['userHistoryVector']], axis=0),\n",
        "      \n",
        "      'context_features': e['contextVector'],\n",
        "  }\n",
        "  \n",
        "  targets = e['clickLabel']\n",
        "    \n",
        "  return inputs, targets\n",
        "\n",
        "def parse_inputs_targets_with_user_activeness(serialized, user_activeness_coef):\n",
        "  e = tf.io.parse_single_example(serialized, features)\n",
        "  \n",
        "  inputs = {\n",
        "      'news_features': tf.concat([e['categoryVector'], tf.math.log(e['newsClickCountVector'] + 1.)], 0),\n",
        "      \n",
        "      'user_features': tf.concat([e['userProfileVector'], tf.math.log(e['userClickCountVector'] + 1.)], 0),\n",
        "      \n",
        "      'user_news_features': tf.math.reduce_prod([e['categoryVector'], e['userHistoryVector']], axis=0),\n",
        "      \n",
        "      'context_features': e['contextVector'],\n",
        "  }\n",
        "  \n",
        "  user_activeness_coef = tf.constant(user_activeness_coef, tf.float32)\n",
        "  targets = tf.dtypes.cast(e['clickLabel'], tf.float32) + user_activeness_coef * e['userActiveness']\n",
        "    \n",
        "  return inputs, targets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGMtPviW5-Aa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_train_dataset(filepaths, batch_size, epochs, user_activeness_coef=None):\n",
        "  dataset = tf.data.TFRecordDataset(filepaths, 'GZIP')\n",
        "  \n",
        "  if user_activeness_coef is None:\n",
        "    func = parse_inputs_targets\n",
        "  else:\n",
        "    func = functools.partial(parse_inputs_targets_with_user_activeness, user_activeness_coef)\n",
        "  \n",
        "  dataset = (\n",
        "      dataset\n",
        "      .map(func)\n",
        "      .batch(batch_size)\n",
        "      .repeat(epochs)\n",
        "      .prefetch(1)\n",
        "  )\n",
        "  \n",
        "  return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "C6rTLodZ_8yc",
        "colab": {}
      },
      "source": [
        "batch_size = 1024\n",
        "epochs = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ibegCe5s_8yj",
        "colab": {}
      },
      "source": [
        "filepaths = sorted(glob.glob(os.path.join(DATA_PATH, 'tfrecords', 'train', '*')))\n",
        "\n",
        "train_dataset = build_train_dataset(filepaths, batch_size, epochs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yuR3ATrV_CYx"
      },
      "source": [
        "# Define models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4IKd3IBQ_CY1",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.activations import relu, sigmoid\n",
        "from tensorflow.keras.layers import Add, Concatenate, Dense, Dot, Input, Lambda, Subtract\n",
        "from tensorflow.keras.losses import BinaryCrossentropy, MeanSquaredError\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9lcjuvms43GO"
      },
      "source": [
        "## 1. Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_HovdzIU43GV",
        "colab": {}
      },
      "source": [
        "def build_lr(input_info):\n",
        "  inputs = [Input(shape=shape, name=name) for name, shape in input_info]\n",
        "  \n",
        "  inputs_concat = Concatenate()(inputs)\n",
        "  \n",
        "  outputs = Dense(1, activation=sigmoid)(inputs_concat)\n",
        "  \n",
        "  model = Model(inputs=inputs, outputs=outputs)  \n",
        "  model.compile(Adam(), loss=BinaryCrossentropy())\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QdnicmRN5AXl"
      },
      "source": [
        "## 2. Factorization Machines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7cZ14iJO5AXr",
        "colab": {}
      },
      "source": [
        "def build_fm(input_info, k_latent):\n",
        "  inputs = [Input(shape=shape, name=name) for name, shape in input_info]\n",
        "  \n",
        "  inputs_concat = Concatenate()(inputs)\n",
        "  \n",
        "  inputs_flat = [Lambda(lambda x: x[:, i:i+1])(inputs_concat) for i in range(inputs_concat.shape[1].value)]\n",
        "  \n",
        "  biases = [Dense(1)(x) for x in inputs_flat]\n",
        "  \n",
        "  factors = [Dense(k_latent)(x) for x in inputs_flat]\n",
        "  \n",
        "  s = Add()(factors)\n",
        "  \n",
        "  diffs = [Subtract()([s, x]) for x in factors]\n",
        "  \n",
        "  dots = [Dot(axes=1)([d, x]) for d, x in zip(diffs, factors)]\n",
        "  \n",
        "  outputs = Add()(dots + biases)\n",
        "  outputs = Dense(1, activation=sigmoid)(outputs)\n",
        "\n",
        "  model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "  model.compile(Adam(), loss=BinaryCrossentropy())\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_TtyG1VV5GZw"
      },
      "source": [
        "## 3. Wide & Deep"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gUBxHMNk5GZ6",
        "colab": {}
      },
      "source": [
        "def build_wd(input_info):\n",
        "  inputs = [Input(shape=shape, name=name) for name, shape in input_info]\n",
        "  \n",
        "  inputs_concat = Concatenate()(inputs)\n",
        "  \n",
        "  wide = Concatenate()(inputs)\n",
        "  \n",
        "  deep = Dense(256, activation=relu)(inputs_concat)\n",
        "  deep = Dense(128, activation=relu)(deep)\n",
        "  \n",
        "  wide_deep = Concatenate()([wide, deep])\n",
        "  \n",
        "  outputs = Dense(1, activation=sigmoid)(wide_deep)\n",
        "  \n",
        "  model = Model(inputs=inputs, outputs=outputs)\n",
        "  \n",
        "  model.compile(Adam(), loss=BinaryCrossentropy())\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KoQZeHXm5K_f"
      },
      "source": [
        "## 4. DN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "t5RhsovA5K_i",
        "colab": {}
      },
      "source": [
        "def build_dqn(input_info, state_indices):\n",
        "  inputs = [Input(shape=shape, name=name) for name, shape in input_info]\n",
        "  \n",
        "  inputs_concat = Concatenate()(inputs)\n",
        "  \n",
        "  value = Concatenate()([inputs[i] for i in state_indices])\n",
        "  value = Dense(256, activation=relu)(value)\n",
        "  value = Dense(128, activation=relu)(value)\n",
        "  value = Dense(1)(value)\n",
        "  \n",
        "  advantage = Dense(256, activation=relu)(inputs_concat)\n",
        "  advantage = Dense(128, activation=relu)(advantage)\n",
        "  advantage = Dense(1)(advantage)\n",
        "\n",
        "  value_advantage = Concatenate()([value, advantage])\n",
        "  \n",
        "  outputs = Dense(1)(value_advantage)\n",
        "\n",
        "  model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "  model.compile(Adam(), loss=MeanSquaredError())\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLBRvjc4uzwc",
        "colab_type": "text"
      },
      "source": [
        "# Train models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFMZNwuTu-FZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_info = (\n",
        "    ('news_features', (34,)),\n",
        "    ('user_features', (124,)),\n",
        "    ('user_news_features', (30,)),\n",
        "    ('context_features', (32,)),\n",
        ")\n",
        "\n",
        "state_indices = (1, 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uGTO4_ZwBJu",
        "colab_type": "text"
      },
      "source": [
        "## 1. Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SF0foVe_1IrZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = build_lr(input_info)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DxA33_Y3Z-X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr.fit(train_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3TTX8G_7Ols",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr.save_weights(os.path.join(DATA_PATH, 'model', 'lr_weights.h5'), overwrite=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yphRbEvAgV2",
        "colab_type": "text"
      },
      "source": [
        "## 2. Factorization Machines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2rrHTySCzGA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fm = build_fm(input_info, k_latent=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wyq_RVRDa0S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fm.fit(train_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "div7d9sw7tVr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fm.save_weights(os.path.join(DATA_PATH, 'model', 'fm_weights.h5'), overwrite=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Kt2K9OF7GlY",
        "colab_type": "text"
      },
      "source": [
        "## 3. Wide & Deep"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uu9LcfG0_UXk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wd = build_wd(input_info)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BttGFwVw_YUp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wd.fit(train_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yPJP8pI_ZkV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wd.save_weights(os.path.join(DATA_PATH, 'model', 'wd_weights.h5'), overwrite=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqP5EnqwU3vb",
        "colab_type": "text"
      },
      "source": [
        "## 4. DN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dTU6TXRBtY2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dqn = build_dqn(input_info, state_indices)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xo9jQS3BuR_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dqn.fit(train_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wq2cZMehBxjs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dqn.save_weights(os.path.join(DATA_PATH, 'model', 'dqn_weights.h5'), overwrite=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9Rro64nBBsS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "user_activeness_coef = 0.05\n",
        "\n",
        "filepaths = sorted(glob.glob(os.path.join(DATA_PATH, 'tfrecords', 'train', '*')))\n",
        "\n",
        "train_dataset_with_user_activeness = build_train_dataset(filepaths, batch_size, epochs, user_activeness_coef)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "844dxy_2B2nF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dqnu = build_dqn(input_info, state_indices)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyQ8PpaiB5AC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dqnu.fit(train_dataset_with_user_activeness)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Um-lb8JEB6sq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dqnu.save_weights(os.path.join(DATA_PATH, 'model', 'dqnu_weights.h5'), overwrite=True)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}